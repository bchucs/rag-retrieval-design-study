[
  {
    "question": "What is the main advantage of the Share approach compared to traditional LoRA methods?",
    "answer": "The Share approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, while maintaining performance comparable to jointly trained models. It enables seamless adaptation across multiple tasks and modalities without the need for multiple adapters.",
    "doc_id": "2602.06043v1",
    "gold_doc_ids": [
      "2602.06043v1"
    ],
    "title": "Shared LoRA Subspaces for almost Strict Continual Learning",
    "question_id": "q_000"
  },
  {
    "question": "What problem does Share aim to address in continual learning?",
    "answer": "Share aims to address the challenges of catastrophic forgetting and the high cost of retraining in continual learning. It does this by learning and dynamically updating a single, shared low-rank subspace that facilitates forward knowledge transfer and minimizes catastrophic interference.",
    "doc_id": "2602.06043v1",
    "gold_doc_ids": [
      "2602.06043v1"
    ],
    "title": "Shared LoRA Subspaces for almost Strict Continual Learning",
    "question_id": "q_001"
  },
  {
    "question": "What is the main purpose of the DyTopo framework in multi-agent systems?",
    "answer": "The main purpose of the DyTopo framework is to reconstruct a sparse directed communication graph at each round of multi-agent reasoning, tailored to the stage-dependent needs of iterative problem solving. It enables agents to output natural-language descriptors for needs and offers, which are semantically matched to optimize communication.",
    "doc_id": "2602.06039v1",
    "gold_doc_ids": [
      "2602.06039v1"
    ],
    "title": "DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching",
    "question_id": "q_002"
  },
  {
    "question": "How does DyTopo enhance communication among agents during multi-round reasoning?",
    "answer": "DyTopo enhances communication by routing private messages along induced edges based on semantic matching of lightweight natural-language query and offer descriptors generated by each agent. This dynamic adjustment allows for more effective coordination that evolves with the changing goals of each round.",
    "doc_id": "2602.06039v1",
    "gold_doc_ids": [
      "2602.06039v1"
    ],
    "title": "DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching",
    "question_id": "q_003"
  },
  {
    "question": "What problem does CommCP aim to address in multi-agent systems?",
    "answer": "CommCP aims to address the information-gathering process in a fully cooperative setting, formalized as the multi-agent multi-task Embodied Question Answering (MM-EQA) problem. This involves effective communication among heterogeneous robots to coordinate efforts without redundancy.",
    "doc_id": "2602.06038v1",
    "gold_doc_ids": [
      "2602.06038v1"
    ],
    "title": "CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction",
    "question_id": "q_004"
  },
  {
    "question": "What methodology does CommCP use to enhance communication reliability?",
    "answer": "CommCP employs conformal prediction to calibrate the generated messages, which minimizes distractions for receivers and enhances communication reliability. This approach is part of the LLM-based decentralized communication framework for MM-EQA.",
    "doc_id": "2602.06038v1",
    "gold_doc_ids": [
      "2602.06038v1"
    ],
    "title": "CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction",
    "question_id": "q_005"
  },
  {
    "question": "What is the primary purpose of the BudgetMem framework?",
    "answer": "The primary purpose of the BudgetMem framework is to provide explicit, query-aware performance-cost control for runtime agent memory. It structures memory processing as a set of memory modules offered in three budget tiers: Low, Mid, and High.",
    "doc_id": "2602.06025v1",
    "gold_doc_ids": [
      "2602.06025v1"
    ],
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "question_id": "q_006"
  },
  {
    "question": "What are the three complementary strategies studied for realizing budget tiers in BudgetMem?",
    "answer": "The three complementary strategies studied for realizing budget tiers in BudgetMem are implementation (method complexity), reasoning (inference behavior), and capacity (module model size). These strategies help in analyzing the strengths and weaknesses of different tiering approaches.",
    "doc_id": "2602.06025v1",
    "gold_doc_ids": [
      "2602.06025v1"
    ],
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "question_id": "q_007"
  },
  {
    "question": "What does the developed data-driven discrete-event simulator (DES) model?",
    "answer": "The DES models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. It allows for the examination of intervention strategies without the need for direct training with human subjects.",
    "doc_id": "2602.06023v1",
    "gold_doc_ids": [
      "2602.06023v1"
    ],
    "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments",
    "question_id": "q_008"
  },
  {
    "question": "What challenge does the research aim to address in evaluating new interventions in VR?",
    "answer": "The research addresses the challenge of needing to recruit new participant cohorts for each condition, which makes large-scale or iterative evaluation difficult. This is particularly restrictive when learning effective intervention strategies that require many training episodes.",
    "doc_id": "2602.06023v1",
    "gold_doc_ids": [
      "2602.06023v1"
    ],
    "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments",
    "question_id": "q_009"
  },
  {
    "question": "What method does CORAL use to capture distributed correctness signals from model internal activations?",
    "answer": "CORAL uses weight-decay MLP probes to capture distributed correctness signals from model internal activations. This regularized inference-time steering method aims to improve model calibration without the need for retraining.",
    "doc_id": "2602.06022v1",
    "gold_doc_ids": [
      "2602.06022v1"
    ],
    "title": "Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering",
    "question_id": "q_010"
  },
  {
    "question": "What are the average improvements in accuracy and expected calibration error (ECE) achieved by CORAL across three 7B-parameter models?",
    "answer": "CORAL consistently improves accuracy by 10% and expected calibration error (ECE) by 50% on average across three 7B-parameter models. Additionally, the method transfers improvements to held-out benchmarks, averaging 14% accuracy and 49% ECE improvements.",
    "doc_id": "2602.06022v1",
    "gold_doc_ids": [
      "2602.06022v1"
    ],
    "title": "Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering",
    "question_id": "q_011"
  },
  {
    "question": "What limitations of the absolute pointwise scoring standard are identified in the abstract?",
    "answer": "The absolute pointwise scoring standard is limited due to stochastic inconsistency and poor alignment with human perception. These limitations necessitate the adoption of alternative evaluation approaches.",
    "doc_id": "2602.06013v1",
    "gold_doc_ids": [
      "2602.06013v1"
    ],
    "title": "GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?",
    "question_id": "q_012"
  },
  {
    "question": "What is the Spearman correlation achieved by the GenArena method compared to pointwise methods?",
    "answer": "The GenArena method achieves a Spearman correlation of 0.86 with the LMArena leaderboard, which drastically surpasses the 0.36 correlation of pointwise methods.",
    "doc_id": "2602.06013v1",
    "gold_doc_ids": [
      "2602.06013v1"
    ],
    "title": "GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?",
    "question_id": "q_013"
  },
  {
    "question": "What is the primary purpose of the AgenticPay framework?",
    "answer": "The AgenticPay framework serves as a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. It aims to evaluate language-mediated economic interaction among multiple agents in a principled setting.",
    "doc_id": "2602.06008v1",
    "gold_doc_ids": [
      "2602.06008v1"
    ],
    "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "question_id": "q_014"
  },
  {
    "question": "How many tasks does the AgenticPay framework support, and what types of markets does it model?",
    "answer": "AgenticPay supports a diverse suite of over 110 tasks, modeling markets where buyers and sellers have private constraints and product-dependent valuations. It includes tasks ranging from bilateral bargaining to many-to-many markets.",
    "doc_id": "2602.06008v1",
    "gold_doc_ids": [
      "2602.06008v1"
    ],
    "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "question_id": "q_015"
  },
  {
    "question": "What are the two attention-based pooling methods proposed in the research for speech emotion recognition?",
    "answer": "The two attention-based pooling methods proposed are Multi-head Attentive Average Pooling and QKV Pooling. These methods are designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features.",
    "doc_id": "2602.06000v1",
    "gold_doc_ids": [
      "2602.06000v1"
    ],
    "title": "Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods",
    "question_id": "q_016"
  },
  {
    "question": "Which datasets were used for experimentation in this study, and which languages do they correspond to?",
    "answer": "The IEMOCAP dataset was used for English, while the ShEMO dataset was used for Persian. The research explores speech emotion recognition capabilities using these datasets in conjunction with the Whisper model.",
    "doc_id": "2602.06000v1",
    "gold_doc_ids": [
      "2602.06000v1"
    ],
    "title": "Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods",
    "question_id": "q_017"
  },
  {
    "question": "What are Diamond Maps and how do they contribute to reward alignment in generative models?",
    "answer": "Diamond Maps are stochastic flow map models designed to enable efficient and accurate alignment to arbitrary rewards at inference time. They allow for the amortization of many simulation steps into a single-step sampler while preserving necessary stochasticity for optimal reward alignment.",
    "doc_id": "2602.05993v1",
    "gold_doc_ids": [
      "2602.05993v1"
    ],
    "title": "Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps",
    "question_id": "q_018"
  },
  {
    "question": "What advantages do Diamond Maps have over existing methods according to the experiments mentioned in the abstract?",
    "answer": "According to the experiments, Diamond Maps achieve stronger reward alignment performance and scale better than existing methods. This indicates their effectiveness in adapting generative models to arbitrary preferences and constraints at inference time.",
    "doc_id": "2602.05993v1",
    "gold_doc_ids": [
      "2602.05993v1"
    ],
    "title": "Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps",
    "question_id": "q_019"
  },
  {
    "question": "What is the primary focus of the RISE-Video benchmark?",
    "answer": "The primary focus of the RISE-Video benchmark is to shift the evaluative focus from surface-level aesthetics to deep cognitive reasoning in generative video models. It aims to explore the capacity of these models to internalize and reason over implicit world rules.",
    "doc_id": "2602.05986v1",
    "gold_doc_ids": [
      "2602.05986v1"
    ],
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "question_id": "q_020"
  },
  {
    "question": "How many samples does the RISE-Video benchmark consist of, and how are they categorized?",
    "answer": "The RISE-Video benchmark comprises 467 meticulously human-annotated samples categorized into eight rigorous categories. These categories are designed to probe model intelligence across various dimensions.",
    "doc_id": "2602.05986v1",
    "gold_doc_ids": [
      "2602.05986v1"
    ],
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "question_id": "q_021"
  },
  {
    "question": "What is the name of the model introduced in the paper for improving motorway traffic forecasting?",
    "answer": "The model introduced in the paper is called the Geographically-aware Transformer-based Traffic Forecasting (GATTF) model. It utilizes geographical relationships between distributed sensors to enhance forecasting accuracy.",
    "doc_id": "2602.05983v1",
    "gold_doc_ids": [
      "2602.05983v1"
    ],
    "title": "Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins",
    "question_id": "q_022"
  },
  {
    "question": "What type of data was used to evaluate the GATTF model?",
    "answer": "The GATTF model was evaluated using real-time data from the Geneva motorway network in Switzerland. The evaluation showed that incorporating geographical awareness improved forecasting accuracy.",
    "doc_id": "2602.05983v1",
    "gold_doc_ids": [
      "2602.05983v1"
    ],
    "title": "Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins",
    "question_id": "q_023"
  },
  {
    "question": "What is the main purpose of the Clifford Kolmogorov-Arnold Network (ClKAN)?",
    "answer": "The main purpose of ClKAN is to provide a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. It aims to address challenges associated with higher dimensional algebras through innovative techniques.",
    "doc_id": "2602.05977v1",
    "gold_doc_ids": [
      "2602.05977v1"
    ],
    "title": "Clifford Kolmogorov-Arnold Networks",
    "question_id": "q_024"
  },
  {
    "question": "What specific method does ClKAN utilize to address the exponential scaling in higher dimensional algebras?",
    "answer": "ClKAN utilizes Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. This method helps in efficiently generating grids for function approximation.",
    "doc_id": "2602.05977v1",
    "gold_doc_ids": [
      "2602.05977v1"
    ],
    "title": "Clifford Kolmogorov-Arnold Networks",
    "question_id": "q_025"
  },
  {
    "question": "How does depth affect loss in large language models according to the findings in the paper?",
    "answer": "The findings indicate that loss scales inversely proportional to depth in large language models, suggesting that functionally similar layers reduce error through ensemble averaging. This implies that increasing depth does not necessarily lead to improved performance.",
    "doc_id": "2602.05970v1",
    "gold_doc_ids": [
      "2602.05970v1"
    ],
    "title": "Inverse Depth Scaling From Most Layers Being Similar",
    "question_id": "q_026"
  },
  {
    "question": "What architectural feature is suggested to contribute to the inefficiency observed in large language models?",
    "answer": "The inefficiency is suggested to arise from the architectural bias of residual networks, which leads to functionally similar layers that may not support compositional learning or the use of depth efficiently.",
    "doc_id": "2602.05970v1",
    "gold_doc_ids": [
      "2602.05970v1"
    ],
    "title": "Inverse Depth Scaling From Most Layers Being Similar",
    "question_id": "q_027"
  },
  {
    "question": "What framework is proposed in the paper to enhance temporal consistency in traffic video generation?",
    "answer": "The paper proposes the Localized Semantic Alignment (LSA) framework, which fine-tunes pre-trained video generation models to enhance temporal consistency by aligning semantic features between ground-truth and generated video clips.",
    "doc_id": "2602.05966v1",
    "gold_doc_ids": [
      "2602.05966v1"
    ],
    "title": "LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation",
    "question_id": "q_028"
  },
  {
    "question": "Which datasets were used to test the effectiveness of the proposed approach in the paper?",
    "answer": "The effectiveness of the proposed approach was tested on the nuScenes and KITTI datasets, demonstrating its ability to enhance temporal consistency in video generation.",
    "doc_id": "2602.05966v1",
    "gold_doc_ids": [
      "2602.05966v1"
    ],
    "title": "LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation",
    "question_id": "q_029"
  },
  {
    "question": "What is the main purpose of the Learning to Share (LTS) mechanism proposed in the paper?",
    "answer": "The main purpose of the Learning to Share (LTS) mechanism is to enable selective cross-team information reuse in parallel agentic systems while controlling context growth. This mechanism aims to reduce overlapping computation and improve the efficiency of parallel execution.",
    "doc_id": "2602.05965v1",
    "gold_doc_ids": [
      "2602.05965v1"
    ],
    "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
    "question_id": "q_030"
  },
  {
    "question": "How is the controller in the LTS mechanism trained?",
    "answer": "The controller in the LTS mechanism is trained using stepwise reinforcement learning with usage-aware credit assignment. This training allows the controller to identify and decide which intermediate agent steps should be added to the global memory bank.",
    "doc_id": "2602.05965v1",
    "gold_doc_ids": [
      "2602.05965v1"
    ],
    "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
    "question_id": "q_031"
  },
  {
    "question": "What does the proposed approach in the paper aim to optimize in flow matching for text-to-image generation?",
    "answer": "The proposed approach aims to learn a condition-dependent source distribution that better exploits rich conditioning signals, enhancing the flow matching objective in text-to-image generation.",
    "doc_id": "2602.05951v1",
    "gold_doc_ids": [
      "2602.05951v1"
    ],
    "title": "Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching",
    "question_id": "q_032"
  },
  {
    "question": "What are the identified key challenges when incorporating conditioning into the source distribution for flow matching?",
    "answer": "The key challenges include distributional collapse and instability, which can arise when conditioning is directly incorporated into the source distribution.",
    "doc_id": "2602.05951v1",
    "gold_doc_ids": [
      "2602.05951v1"
    ],
    "title": "Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching",
    "question_id": "q_033"
  },
  {
    "question": "What percentage of the analyzed papers contained Total Fabrication hallucinations?",
    "answer": "Total Fabrication hallucinations were found in 66% of the analyzed citations. This was the most common failure mode identified in the study.",
    "doc_id": "2602.05930v1",
    "gold_doc_ids": [
      "2602.05930v1"
    ],
    "title": "Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025",
    "question_id": "q_034"
  },
  {
    "question": "How many categories are included in the taxonomy developed for classifying hallucinations?",
    "answer": "The study develops a five-category taxonomy to classify hallucinations by their failure mode. These categories include Total Fabrication, Partial Attribute Corruption, Identifier Hijacking, Placeholder Hallucination, and Semantic Hallucination.",
    "doc_id": "2602.05930v1",
    "gold_doc_ids": [
      "2602.05930v1"
    ],
    "title": "Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025",
    "question_id": "q_035"
  },
  {
    "question": "What are the three variants of the Advantage Actor-Critic (A2C) agent implemented in this study?",
    "answer": "The three variants of the Advantage Actor-Critic (A2C) agent implemented in this study are classical, full quantum, and hybrid variants. These variants integrate transformer architectures to enhance routing policy learning.",
    "doc_id": "2602.05920v1",
    "gold_doc_ids": [
      "2602.05920v1"
    ],
    "title": "Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem",
    "question_id": "q_036"
  },
  {
    "question": "How many clients and vehicles were considered in the experiments for the Capacitated Vehicle Routing Problem?",
    "answer": "The experiments for the Capacitated Vehicle Routing Problem considered 20 clients and 4 vehicles. The focus was on multi-vehicle scenarios with capacity constraints.",
    "doc_id": "2602.05920v1",
    "gold_doc_ids": [
      "2602.05920v1"
    ],
    "title": "Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem",
    "question_id": "q_037"
  },
  {
    "question": "What is the main advantage of the DFlash framework compared to existing speculative decoding methods?",
    "answer": "DFlash employs a lightweight block diffusion model for parallel drafting, enabling efficient drafting with high-quality outputs and higher acceptance rates. This approach allows for over 6x lossless acceleration and up to 2.5x higher speedup than the state-of-the-art method EAGLE-3.",
    "doc_id": "2602.06036v1",
    "gold_doc_ids": [
      "2602.06036v1"
    ],
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "question_id": "q_038"
  },
  {
    "question": "How does DFlash enhance the drafting process in comparison to autoregressive models?",
    "answer": "DFlash generates draft tokens in a single forward pass and conditions the draft model on context features extracted from the target model, which mitigates the sequential limitations of autoregressive drafting. This results in improved efficiency and speed during the decoding process.",
    "doc_id": "2602.06036v1",
    "gold_doc_ids": [
      "2602.06036v1"
    ],
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "question_id": "q_039"
  },
  {
    "question": "What is the primary advantage of the proposed approach for multi-token prediction compared to existing techniques?",
    "answer": "The proposed approach allows for converting a pretrained autoregressive language model into a fast standalone multi-token prediction model without the need for auxiliary speculator models or complex inference pipelines. This results in a simpler implementation while maintaining the same deployment conditions as the original model.",
    "doc_id": "2602.06019v1",
    "gold_doc_ids": [
      "2602.06019v1"
    ],
    "title": "Multi-Token Prediction via Self-Distillation",
    "question_id": "q_040"
  },
  {
    "question": "What performance improvement does the method achieve on GSM8K regarding decoding speed and accuracy?",
    "answer": "The method produces models that can decode more than three times faster on average while maintaining less than a 5% drop in accuracy compared to single token decoding performance on the GSM8K dataset.",
    "doc_id": "2602.06019v1",
    "gold_doc_ids": [
      "2602.06019v1"
    ],
    "title": "Multi-Token Prediction via Self-Distillation",
    "question_id": "q_041"
  },
  {
    "question": "What factors were systematically varied to evaluate the performance of large language models in PTSD severity estimation?",
    "answer": "The factors varied included contextual knowledge such as subscale definitions, distribution summary, and interview questions, as well as modeling strategies like zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling, and nine ensemble methods.",
    "doc_id": "2602.06015v1",
    "gold_doc_ids": [
      "2602.06015v1"
    ],
    "title": "A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies",
    "question_id": "q_042"
  },
  {
    "question": "According to the findings, what is the relationship between reasoning effort and estimation accuracy when using large language models?",
    "answer": "The findings indicate that increased reasoning effort leads to better estimation accuracy, suggesting that the amount of reasoning applied during the assessment is a critical factor in the performance of the models.",
    "doc_id": "2602.06015v1",
    "gold_doc_ids": [
      "2602.06015v1"
    ],
    "title": "A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies",
    "question_id": "q_043"
  },
  {
    "question": "What is the main limitation of the widely-used fixed, predefined block scheduling method in diffusion large language models?",
    "answer": "The main limitation of the fixed, predefined block scheduling method is that it is agnostic to semantic difficulty, which can lead to premature commitments to uncertain positions and delays for easy positions near block boundaries, resulting in suboptimal quality and efficiency.",
    "doc_id": "2602.05992v1",
    "gold_doc_ids": [
      "2602.05992v1"
    ],
    "title": "DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs",
    "question_id": "q_044"
  },
  {
    "question": "What are the two proposed methods in the paper to improve inference for diffusion large language models?",
    "answer": "The two proposed methods are Dynamic Sliding Block (DSB), which utilizes a sliding block with a dynamic size for scheduling, and DSB Cache, a training-free KV-cache mechanism designed specifically for DSB. Both methods aim to enhance generation quality and inference efficiency.",
    "doc_id": "2602.05992v1",
    "gold_doc_ids": [
      "2602.05992v1"
    ],
    "title": "DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs",
    "question_id": "q_045"
  },
  {
    "question": "What is the main purpose of the SAGE benchmark introduced in the research?",
    "answer": "The SAGE benchmark is designed for scientific literature retrieval and comprises 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus. It aims to investigate the effectiveness of LLM-based retrievers in deep research agent workflows.",
    "doc_id": "2602.05975v1",
    "gold_doc_ids": [
      "2602.05975v1"
    ],
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "question_id": "q_046"
  },
  {
    "question": "What performance difference was observed between BM25 and LLM-based retrievers in the evaluation?",
    "answer": "BM25 significantly outperformed LLM-based retrievers by approximately 30%, indicating that existing agents struggle with reasoning-intensive retrieval and tend to generate keyword-oriented sub-queries. This performance gap highlighted the limitations of LLM-based methods in this context.",
    "doc_id": "2602.05975v1",
    "gold_doc_ids": [
      "2602.05975v1"
    ],
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "question_id": "q_047"
  },
  {
    "question": "What types of metrics are extracted from the participant-specific semantic trajectories in the study?",
    "answer": "The study extracts geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These metrics capture both scalar and directional aspects of semantic navigation.",
    "doc_id": "2602.05971v1",
    "gold_doc_ids": [
      "2602.05971v1"
    ],
    "title": "Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space",
    "question_id": "q_048"
  },
  {
    "question": "On how many datasets and in what contexts was the framework evaluated?",
    "answer": "The framework was evaluated on four datasets across different languages, specifically in the contexts of Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. This evaluation spans different property generation tasks.",
    "doc_id": "2602.05971v1",
    "gold_doc_ids": [
      "2602.05971v1"
    ],
    "title": "Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space",
    "question_id": "q_049"
  },
  {
    "question": "What is the primary method proposed in the paper to improve multilingual reasoning?",
    "answer": "The primary method proposed is TRIT (Translation-Reasoning Integrated Training), which integrates the training of translation into multilingual reasoning to enhance multilingual question understanding and response generation.",
    "doc_id": "2602.05940v1",
    "gold_doc_ids": [
      "2602.05940v1"
    ],
    "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
    "question_id": "q_050"
  },
  {
    "question": "How much does the proposed method improve cross-lingual question alignment and translation quality according to the analysis?",
    "answer": "The proposed method improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, achieving gains up to 8.4 COMET points on FLORES-200.",
    "doc_id": "2602.05940v1",
    "gold_doc_ids": [
      "2602.05940v1"
    ],
    "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
    "question_id": "q_051"
  },
  {
    "question": "What new corpus is released in the study, and how is it different from prior work?",
    "answer": "The study releases the Multilingual European Value Survey (MEVS), which comprises human-translated survey questions aligned in 8 European languages. This differs from prior work that relied on machine translation or ad hoc prompts.",
    "doc_id": "2602.05932v1",
    "gold_doc_ids": [
      "2602.05932v1"
    ],
    "title": "Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions",
    "question_id": "q_052"
  },
  {
    "question": "What was the primary objective of the research conducted in the paper?",
    "answer": "The primary objective was to investigate language-induced variation in value-laden MCQ responses among multilingual LLMs. The research aimed to determine whether these models behave like theoretical polyglots or express different values like a multitude of monolingual models.",
    "doc_id": "2602.05932v1",
    "gold_doc_ids": [
      "2602.05932v1"
    ],
    "title": "Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions",
    "question_id": "q_053"
  },
  {
    "question": "What method does KV-CoRE use to quantify the data-dependent low-rank compressibility of kv-caches?",
    "answer": "KV-CoRE employs an SVD-based method to compute the optimal low-rank approximation under the Frobenius norm. This approach allows for efficient dataset-level, layer-wise evaluation of kv-cache compressibility.",
    "doc_id": "2602.05929v1",
    "gold_doc_ids": [
      "2602.05929v1"
    ],
    "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
    "question_id": "q_054"
  },
  {
    "question": "What is the relationship between Normalized Effective Rank and performance degradation under compression according to the study?",
    "answer": "The study shows that the Normalized Effective Rank, which is used as a metric of compressibility, correlates strongly with performance degradation under compression. This indicates that as compressibility increases, performance may be adversely affected.",
    "doc_id": "2602.05929v1",
    "gold_doc_ids": [
      "2602.05929v1"
    ],
    "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
    "question_id": "q_055"
  },
  {
    "question": "What is the primary purpose of Codified Finite-State Machines (CFSMs) as introduced in the paper?",
    "answer": "The primary purpose of CFSMs is to automatically codify textual character profiles into finite-state machines using LLM-based coding, which helps to extract key states and transitions directly from the profile. This produces interpretable structures that enforce character consistency in role-playing scenarios.",
    "doc_id": "2602.05905v1",
    "gold_doc_ids": [
      "2602.05905v1"
    ],
    "title": "Codified Finite-state Machines for Role-playing",
    "question_id": "q_056"
  },
  {
    "question": "How do Codified Probabilistic Finite-State Machines (CPFSMs) extend the functionality of CFSMs?",
    "answer": "CPFSMs extend the functionality of CFSMs by modeling transitions as probability distributions over states, which allows them to capture uncertainty and variability in character states. This enhancement aims to improve performance in both structured tasks and open-ended stochastic state exploration.",
    "doc_id": "2602.05905v1",
    "gold_doc_ids": [
      "2602.05905v1"
    ],
    "title": "Codified Finite-state Machines for Role-playing",
    "question_id": "q_057"
  },
  {
    "question": "What is the main problem that small reasoning models (SRMs) face according to the abstract?",
    "answer": "Small reasoning models (SRMs) are prone to faithfulness hallucinations, particularly in intermediate reasoning steps. This issue can lead to unfaithful reasoning even when the final answer is correct.",
    "doc_id": "2602.05897v1",
    "gold_doc_ids": [
      "2602.05897v1"
    ],
    "title": "Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models",
    "question_id": "q_058"
  },
  {
    "question": "What method does the paper propose to mitigate the issue of faithfulness hallucinations in SRMs?",
    "answer": "The paper proposes Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), which introduces step-level supervision through explicit faithfulness rewards and an implicit truncated resampling strategy to generate contrastive signals from faithful prefixes.",
    "doc_id": "2602.05897v1",
    "gold_doc_ids": [
      "2602.05897v1"
    ],
    "title": "Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models",
    "question_id": "q_059"
  },
  {
    "question": "What is the main contribution of DFPO in the context of reinforcement learning systems?",
    "answer": "DFPO, or Distributional Value Flow Policy Optimization with Conditional Risk and Consistency Control, introduces a robust distributional RL framework that models values as continuous flows across time steps, improving the representation of state information for better advantage estimation.",
    "doc_id": "2602.05890v1",
    "gold_doc_ids": [
      "2602.05890v1"
    ],
    "title": "DFPO: Scaling Value Modeling via Distributional Flow towards Robust and Generalizable LLM Post-Training",
    "question_id": "q_060"
  },
  {
    "question": "How does DFPO aim to improve training stability under noisy feedback?",
    "answer": "DFPO integrates conditional risk control and consistency constraints along value flow trajectories to stabilize training under noisy feedback, addressing challenges in reinforcement learning.",
    "doc_id": "2602.05890v1",
    "gold_doc_ids": [
      "2602.05890v1"
    ],
    "title": "DFPO: Scaling Value Modeling via Distributional Flow towards Robust and Generalizable LLM Post-Training",
    "question_id": "q_061"
  },
  {
    "question": "What is KernelGYM and what purpose does it serve in the context of the research?",
    "answer": "KernelGYM is a robust distributed GPU environment designed to support reward hacking checks, data collection from multi-turn interactions, and long-term reinforcement learning training. It serves as the foundation for studying reinforcement learning methods for kernel generation.",
    "doc_id": "2602.05885v1",
    "gold_doc_ids": [
      "2602.05885v1"
    ],
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "question_id": "q_062"
  },
  {
    "question": "What are the performance results of the Dr.Kernel-14B model in comparison to Claude-4.5-Sonnet and GPT-5?",
    "answer": "The Dr.Kernel-14B model achieves a performance competitive with Claude-4.5-Sonnet in Kernelbench, with 31.6% of generated kernels on the Level-2 subset achieving at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet's 26.7% and GPT-5's 28.6%. When selecting the best candidate across all turns, the speedup rate increases to 47.8%.",
    "doc_id": "2602.05885v1",
    "gold_doc_ids": [
      "2602.05885v1"
    ],
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "question_id": "q_063"
  },
  {
    "question": "What languages does EuroLLM-22B support?",
    "answer": "EuroLLM-22B supports all 24 official European Union languages and 11 additional languages. This is aimed at addressing the underrepresentation of European languages in existing open large language models.",
    "doc_id": "2602.05879v1",
    "gold_doc_ids": [
      "2602.05879v1"
    ],
    "title": "EuroLLM-22B: Technical Report",
    "question_id": "q_064"
  },
  {
    "question": "What aspects of EuroLLM-22B's development are covered in the report?",
    "answer": "The report provides a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. These elements contribute to the model's effectiveness and performance.",
    "doc_id": "2602.05879v1",
    "gold_doc_ids": [
      "2602.05879v1"
    ],
    "title": "EuroLLM-22B: Technical Report",
    "question_id": "q_065"
  },
  {
    "question": "What does the xList-Hate framework decompose hate speech detection into?",
    "answer": "The xList-Hate framework decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. This approach allows for independent answers from a large language model, capturing hateful content features.",
    "doc_id": "2602.05874v1",
    "gold_doc_ids": [
      "2602.05874v1"
    ],
    "title": "xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection",
    "question_id": "q_066"
  },
  {
    "question": "How does the xList-Hate framework improve upon traditional supervised methods in hate speech detection?",
    "answer": "The xList-Hate framework consistently improves cross-dataset robustness and relative performance under domain shift compared to traditional supervised methods. It is less sensitive to annotation inconsistency and contextual ambiguity, thus enhancing the overall interpretability and reliability of predictions.",
    "doc_id": "2602.05874v1",
    "gold_doc_ids": [
      "2602.05874v1"
    ],
    "title": "xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection",
    "question_id": "q_067"
  },
  {
    "question": "What is the main objective of introducing Constrained GRPO?",
    "answer": "The main objective of introducing Constrained GRPO is to extend the Group Relative Policy Optimization framework to allow for constrained policy optimization while ensuring that constraints are specified via indicator cost functions. This enables direct optimization of violation rates through a Lagrangian relaxation.",
    "doc_id": "2602.05863v1",
    "gold_doc_ids": [
      "2602.05863v1"
    ],
    "title": "Constrained Group Relative Policy Optimization",
    "question_id": "q_068"
  },
  {
    "question": "What effect does a naive multi-component treatment in advantage estimation have on constrained learning, according to the abstract?",
    "answer": "A naive multi-component treatment in advantage estimation can break constrained learning by distorting the relative importance of different objective terms due to mismatched component-wise standard deviations. This corruption of the Lagrangian signal prevents meaningful constraint enforcement.",
    "doc_id": "2602.05863v1",
    "gold_doc_ids": [
      "2602.05863v1"
    ],
    "title": "Constrained Group Relative Policy Optimization",
    "question_id": "q_069"
  },
  {
    "question": "What is DLM-Scope and what does it aim to achieve?",
    "answer": "DLM-Scope is the first sparse autoencoder (SAE)-based interpretability framework for diffusion language models (DLMs). It aims to develop tailored mechanistic interpretability tools for DLMs and demonstrates that trained Top-K SAEs can extract interpretable features effectively.",
    "doc_id": "2602.05859v1",
    "gold_doc_ids": [
      "2602.05859v1"
    ],
    "title": "DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders",
    "question_id": "q_070"
  },
  {
    "question": "How does the insertion of SAEs affect DLMs compared to autoregressive LLMs?",
    "answer": "Inserting SAEs into autoregressive LLMs typically incurs a loss penalty, whereas in DLMs, it can reduce cross-entropy loss when applied to early layers. This phenomenon is either absent or markedly weaker in LLMs.",
    "doc_id": "2602.05859v1",
    "gold_doc_ids": [
      "2602.05859v1"
    ],
    "title": "DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders",
    "question_id": "q_071"
  },
  {
    "question": "What is the main advantage of the RRAttention method compared to existing dynamic sparse attention methods?",
    "answer": "RRAttention achieves query independence while enabling efficient global pattern discovery with stride-level aggregation and reduces complexity from O(L^2) to O(L^2/S^2). It also recovers over 99% of full attention performance while computing only half of the attention blocks.",
    "doc_id": "2602.05853v1",
    "gold_doc_ids": [
      "2602.05853v1"
    ],
    "title": "RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference",
    "question_id": "q_072"
  },
  {
    "question": "What is the speedup achieved by RRAttention at a context length of 128K?",
    "answer": "RRAttention achieves a speedup of 2.4 times at a context length of 128K while maintaining high performance.",
    "doc_id": "2602.05853v1",
    "gold_doc_ids": [
      "2602.05853v1"
    ],
    "title": "RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference",
    "question_id": "q_073"
  },
  {
    "question": "What is the main purpose of introducing Surjective Pseudo-invertible Neural Networks (SPNN)?",
    "answer": "The main purpose of introducing SPNN is to create a class of architectures that can accommodate a tractable non-linear Moore-Penrose Pseudo-inverse (PInv). This allows for the application of the non-linear PInv in the context of neural networks.",
    "doc_id": "2602.06042v1",
    "gold_doc_ids": [
      "2602.06042v1"
    ],
    "title": "Pseudo-Invertible Neural Networks",
    "question_id": "q_074"
  },
  {
    "question": "How does the proposed Non-Linear Back-Projection (NLBP) method ensure consistency for non-linear mappings?",
    "answer": "The Non-Linear Back-Projection (NLBP) method guarantees consistency for non-linear mappings by utilizing the defined PInv to ensure that a sample is moved to its closest consistent state that satisfies the equation $f(x)=y$. This is achieved through the geometric property of null-space projection.",
    "doc_id": "2602.06042v1",
    "gold_doc_ids": [
      "2602.06042v1"
    ],
    "title": "Pseudo-Invertible Neural Networks",
    "question_id": "q_075"
  },
  {
    "question": "What is the primary purpose of the CAMCUE framework introduced in the paper?",
    "answer": "The primary purpose of the CAMCUE framework is to use camera pose as an explicit geometric anchor for cross-view fusion and novel-view reasoning in multi-image spatial reasoning tasks. It aims to improve coherence in 3D understanding from multi-view observations and facilitate reasoning from language-specified viewpoints.",
    "doc_id": "2602.06041v1",
    "gold_doc_ids": [
      "2602.06041v1"
    ],
    "title": "Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning",
    "question_id": "q_076"
  },
  {
    "question": "How many training and test instances are included in the CAMCUE-DATA dataset?",
    "answer": "The CAMCUE-DATA dataset includes 27,668 training instances and 508 test instances that pair multi-view images and poses with diverse target-viewpoint descriptions and perspective-shift questions.",
    "doc_id": "2602.06041v1",
    "gold_doc_ids": [
      "2602.06041v1"
    ],
    "title": "Predicting Camera Pose from Perspective Descriptions for Spatial Reasoning",
    "question_id": "q_077"
  },
  {
    "question": "What are the three reasoning modes that SwimBird can switch among?",
    "answer": "SwimBird can dynamically switch among three reasoning modes: (1) text-only reasoning, (2) vision-only reasoning using continuous hidden states as visual thoughts, and (3) interleaved vision-text reasoning.",
    "doc_id": "2602.06040v1",
    "gold_doc_ids": [
      "2602.06040v1"
    ],
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "question_id": "q_078"
  },
  {
    "question": "What is the purpose of the hybrid autoregressive formulation used in SwimBird?",
    "answer": "The hybrid autoregressive formulation in SwimBird unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts, enabling flexible and adaptive reasoning mode selection.",
    "doc_id": "2602.06040v1",
    "gold_doc_ids": [
      "2602.06040v1"
    ],
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "question_id": "q_079"
  },
  {
    "question": "What is the main contribution of the GeoThinker framework compared to existing integration strategies for spatial reasoning?",
    "answer": "GeoThinker shifts the paradigm from passive fusion to active perception, enabling selective retrieval of geometric evidence based on internal reasoning demands rather than indiscriminate feature mixing. This approach aims to reduce semantic-geometry misalignment and redundant signals.",
    "doc_id": "2602.06037v1",
    "gold_doc_ids": [
      "2602.06037v1"
    ],
    "title": "Thinking with Geometry: Active Geometry Integration for Spatial Reasoning",
    "question_id": "q_080"
  },
  {
    "question": "What specific score did GeoThinker achieve on the VSI-Bench, and what does this indicate about its performance?",
    "answer": "GeoThinker achieved a peak score of 72.6 on the VSI-Bench, indicating that it sets a new state-of-the-art in spatial intelligence and demonstrates robust generalization in spatial perception across various complex scenarios.",
    "doc_id": "2602.06037v1",
    "gold_doc_ids": [
      "2602.06037v1"
    ],
    "title": "Thinking with Geometry: Active Geometry Integration for Spatial Reasoning",
    "question_id": "q_081"
  },
  {
    "question": "What is the primary goal of the InterPrior framework?",
    "answer": "The primary goal of the InterPrior framework is to enable humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. It achieves this through a unified generative controller learned via imitation pretraining and reinforcement learning.",
    "doc_id": "2602.06035v1",
    "gold_doc_ids": [
      "2602.06035v1"
    ],
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "question_id": "q_082"
  },
  {
    "question": "How does InterPrior improve the generalization of the distilled policy?",
    "answer": "InterPrior improves the generalization of the distilled policy by applying data augmentation with physical perturbations and performing reinforcement learning finetuning. This approach enhances competence on unseen goals and initializations, allowing the system to incorporate new behaviors such as interactions with unseen objects.",
    "doc_id": "2602.06035v1",
    "gold_doc_ids": [
      "2602.06035v1"
    ],
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "question_id": "q_083"
  },
  {
    "question": "What is the primary focus of the proposed V-Retrver framework in the context of multimodal retrieval?",
    "answer": "The primary focus of V-Retrver is to reformulate multimodal retrieval as an evidence-driven agentic reasoning process grounded in visual inspection, allowing for the selective acquisition of visual evidence during reasoning.",
    "doc_id": "2602.06034v1",
    "gold_doc_ids": [
      "2602.06034v1"
    ],
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "question_id": "q_084"
  },
  {
    "question": "What strategy is adopted to train the evidence-gathering retrieval agent in V-Retrver?",
    "answer": "The training strategy for the evidence-gathering retrieval agent in V-Retrver combines supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective.",
    "doc_id": "2602.06034v1",
    "gold_doc_ids": [
      "2602.06034v1"
    ],
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "question_id": "q_085"
  },
  {
    "question": "What is the primary goal of the Splat and Distill framework introduced in the paper?",
    "answer": "The primary goal of the Splat and Distill framework is to instill robust 3D awareness into 2D Vision Foundation Models by augmenting the teacher model with a fast, feed-forward 3D reconstruction pipeline. This is achieved by lifting 2D features into an explicit 3D Gaussian representation and using these 3D features to supervise the student model.",
    "doc_id": "2602.06032v1",
    "gold_doc_ids": [
      "2602.06032v1"
    ],
    "title": "Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation",
    "question_id": "q_086"
  },
  {
    "question": "Which downstream tasks were evaluated to assess the performance of the Splat and Distill method?",
    "answer": "The Splat and Distill method was evaluated on a suite of downstream tasks, including monocular depth estimation, surface normal estimation, multi-view correspondence, and semantic segmentation. The method significantly outperformed prior works in these tasks.",
    "doc_id": "2602.06032v1",
    "gold_doc_ids": [
      "2602.06032v1"
    ],
    "title": "Splat and Distill: Augmenting Teachers with Feed-Forward 3D Reconstruction For 3D-Aware Distillation",
    "question_id": "q_087"
  },
  {
    "question": "What is the key issue addressed by the Context Forcing framework in video generation?",
    "answer": "The key issue addressed is the student-teacher mismatch, where the short-context teacher cannot guide the long-context student effectively due to its inability to access long-term history. This mismatch prevents the student from achieving global temporal dependencies and caps its context length.",
    "doc_id": "2602.06028v1",
    "gold_doc_ids": [
      "2602.06028v1"
    ],
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "question_id": "q_088"
  },
  {
    "question": "How does the Context Forcing framework improve video generation compared to state-of-the-art methods?",
    "answer": "Context Forcing improves video generation by training a long-context student with a long-context teacher, eliminating supervision mismatch and enabling robust training for long-term consistency. It achieves effective context lengths exceeding 20 seconds, which is 2 to 10 times longer than existing methods like LongLive and Infinite-RoPE.",
    "doc_id": "2602.06028v1",
    "gold_doc_ids": [
      "2602.06028v1"
    ],
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "question_id": "q_089"
  },
  {
    "question": "What is the main advantage of the MambaVF framework compared to existing video fusion methods?",
    "answer": "The main advantage of MambaVF is its ability to perform temporal modeling without explicit motion estimation, which significantly reduces computation and memory costs. It captures long-range temporal dependencies with linear complexity, leading to high efficiency.",
    "doc_id": "2602.06017v1",
    "gold_doc_ids": [
      "2602.06017v1"
    ],
    "title": "MambaVF: State Space Model for Efficient Video Fusion",
    "question_id": "q_090"
  },
  {
    "question": "What percentage reductions in parameters and computational FLOPs does MambaVF achieve compared to existing methods?",
    "answer": "MambaVF achieves reductions of up to 92.25% in parameters and 88.79% in computational FLOPs compared to existing methods. Additionally, it offers a 2.1x speedup.",
    "doc_id": "2602.06017v1",
    "gold_doc_ids": [
      "2602.06017v1"
    ],
    "title": "MambaVF: State Space Model for Efficient Video Fusion",
    "question_id": "q_091"
  },
  {
    "question": "What is the main objective of the VisRefiner framework in the context of screenshot-to-code generation?",
    "answer": "The main objective of the VisRefiner framework is to enable models to learn from visual differences between rendered predictions and reference designs, thereby improving the translation of user interface screenshots into executable frontend code.",
    "doc_id": "2602.05998v1",
    "gold_doc_ids": [
      "2602.05998v1"
    ],
    "title": "VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation",
    "question_id": "q_092"
  },
  {
    "question": "What method does VisRefiner introduce to improve the generated code during the self-refinement stage?",
    "answer": "VisRefiner introduces a reinforcement learning stage for self-refinement, where the model improves its generated code by observing the rendered output and the target design, identifying their visual differences, and updating the code accordingly.",
    "doc_id": "2602.05998v1",
    "gold_doc_ids": [
      "2602.05998v1"
    ],
    "title": "VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation",
    "question_id": "q_093"
  },
  {
    "question": "What are the main components of the proposed Multi-scale Global-Instance Prompt Tuning (MGIPT) method?",
    "answer": "MGIPT consists of an Adaptive-scale Instance Prompt (AIP) and a Multi-scale Global-level Prompt (MGP). AIP dynamically learns lightweight and instance-specific prompts, while MGP captures domain-level knowledge across different scales.",
    "doc_id": "2602.05937v1",
    "gold_doc_ids": [
      "2602.05937v1"
    ],
    "title": "Multi-Scale Global-Instance Prompt Tuning for Continual Test-time Adaptation in Medical Image Segmentation",
    "question_id": "q_094"
  },
  {
    "question": "What limitations of existing Continual Test-Time Adaptation (CTTA) methods does MGIPT aim to address?",
    "answer": "MGIPT aims to address several limitations of existing CTTA methods, including lacking multi-scale prompt diversity, inadequate incorporation of instance-specific knowledge, and the risk of privacy leakage. These issues can lead to error accumulation and catastrophic forgetting during long-term adaptation.",
    "doc_id": "2602.05937v1",
    "gold_doc_ids": [
      "2602.05937v1"
    ],
    "title": "Multi-Scale Global-Instance Prompt Tuning for Continual Test-time Adaptation in Medical Image Segmentation",
    "question_id": "q_095"
  },
  {
    "question": "What is the primary issue with existing CLIP compression methods as mentioned in the abstract?",
    "answer": "Existing CLIP compression methods typically reduce the size of pre-trained CLIP weights, but they often compromise the feature presentation ability, especially under extreme compression. This limitation arises from the use of select-based weight inheritance methods.",
    "doc_id": "2602.05909v1",
    "gold_doc_ids": [
      "2602.05909v1"
    ],
    "title": "CLIP-Map: Structured Matrix Mapping for Parameter-Efficient CLIP Compression",
    "question_id": "q_096"
  },
  {
    "question": "What novel approach does the proposed CLIP-Map framework utilize for CLIP compression?",
    "answer": "The CLIP-Map framework employs a mapping-based approach that uses learnable matrices to map and combine pretrained weights through Full-Mapping with Kronecker Factorization. This method aims to preserve as much information from the original weights as possible.",
    "doc_id": "2602.05909v1",
    "gold_doc_ids": [
      "2602.05909v1"
    ],
    "title": "CLIP-Map: Structured Matrix Mapping for Parameter-Efficient CLIP Compression",
    "question_id": "q_097"
  }
]