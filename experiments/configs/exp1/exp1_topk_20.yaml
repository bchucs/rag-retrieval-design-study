# Experiment 1: Context Quantity - How Much to Retrieve
# Configuration: top_k = 20 (maximum context)
# Research Question: Does excessive context lead to dilution and hallucination?

experiment_name: "exp1_topk_20"

# Data configuration
data:
  corpus: "arxiv_cs"
  data_dir: "data/raw"

# Chunking configuration (keep constant for Experiment 1)
chunking:
  chunk_size: 512  # tokens
  overlap: 0  # tokens
  encoding_name: "cl100k_base"

# Embedding configuration (fixed across all experiments)
embedding:
  model_name: "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
  batch_size: 32
  cache_dir: null

# Indexing configuration (keep constant for Experiment 1)
indexing:
  index_type: "flat"
  n_clusters: 100
  nprobe: 10

# Retrieval configuration - EXPERIMENTAL VARIABLE
retrieval:
  top_k: 20  # Maximum context
  distance_threshold: null

# Generation configuration (fixed across all experiments)
generation:
  model_name: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: 500

# Evaluation configuration
evaluation:
  questions_file: "data/questions/eval_questions.json"
  output_dir: "results"
